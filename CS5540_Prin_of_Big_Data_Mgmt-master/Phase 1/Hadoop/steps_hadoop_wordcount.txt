cd Desktop/health/
vthotigar@ubuntu:~/Desktop/health$ ll
total 20520
drwxrwxr-x 2 vthotigar vthotigar     4096 Sep 28 21:48 ./
drwxr-xr-x 6 vthotigar vthotigar     4096 Sep 28 21:45 ../
-rw-r--r-- 1 vthotigar vthotigar  1847775 Sep 28 21:38 data1.txt
-rw-r--r-- 1 vthotigar vthotigar  1618776 Sep 28 21:38 data2.txt
-rw-r--r-- 1 vthotigar vthotigar  4230895 Sep 28 21:39 data3.txt
-rw-r--r-- 1 vthotigar vthotigar 13299417 Sep 28 21:30 tweetsdata.txt
vthotigar@ubuntu:~/Desktop/health$ cd
vthotigar@ubuntu:~$ jps
2610 Jps
vthotigar@ubuntu:~$ cd $HADOOP_HOME
vthotigar@ubuntu:~/hadoop$ sbin/start-dfs.sh 
Starting namenodes on [localhost]
localhost: starting namenode, logging to /home/vthotigar/hadoop/logs/hadoop-vthotigar-namenode-ubuntu.out
localhost: starting datanode, logging to /home/vthotigar/hadoop/logs/hadoop-vthotigar-datanode-ubuntu.out
Starting secondary namenodes [0.0.0.0]
0.0.0.0: starting secondarynamenode, logging to /home/vthotigar/hadoop/logs/hadoop-vthotigar-secondarynamenode-ubuntu.out
vthotigar@ubuntu:~/hadoop$ sbin/start-yarn.sh 
starting yarn daemons
starting resourcemanager, logging to /home/vthotigar/hadoop/logs/yarn-vthotigar-resourcemanager-ubuntu.out
localhost: starting nodemanager, logging to /home/vthotigar/hadoop/logs/yarn-vthotigar-nodemanager-ubuntu.out
vthotigar@ubuntu:~/hadoop$ jps
3014 DataNode
3463 ResourceManager
3258 SecondaryNameNode
3629 NodeManager
2846 NameNode
3791 Jps
vthotigar@ubuntu:~/hadoop$ hdfs dfs -mkdir /bigdata/health
vthotigar@ubuntu:~/hadoop$ hdfs dfs -copyFromLocal /home/vthotigar/Desktop/health /bigdata/health
vthotigar@ubuntu:~/hadoop$ hdfs dfs -copyFromLocal /home/vthotigar/Desktop/health /bigdata
vthotigar@ubuntu:~/hadoop$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.3.jar wordcount /bigdata/health/* /output/health
18/09/28 22:05:54 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
18/09/28 22:05:54 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://localhost:9000/output/health already exists
	at org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:146)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:268)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:141)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1836)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1359)
	at org.apache.hadoop.examples.WordCount.main(WordCount.java:87)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)
	at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
	at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:234)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:148)
vthotigar@ubuntu:~/hadoop$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.3.jar wordcount /bigdata/health/* /output/health
18/09/28 22:06:19 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
18/09/28 22:06:19 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
18/09/28 22:06:19 INFO input.FileInputFormat: Total input files to process : 5
18/09/28 22:06:19 INFO mapreduce.JobSubmitter: number of splits:5
18/09/28 22:06:19 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local899174303_0001
18/09/28 22:06:20 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
18/09/28 22:06:20 INFO mapreduce.Job: Running job: job_local899174303_0001
18/09/28 22:06:20 INFO mapred.LocalJobRunner: OutputCommitter set in config null
18/09/28 22:06:20 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/28 22:06:20 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/09/28 22:06:20 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
18/09/28 22:06:20 INFO mapred.LocalJobRunner: Waiting for map tasks
18/09/28 22:06:20 INFO mapred.LocalJobRunner: Starting task: attempt_local899174303_0001_m_000000_0
18/09/28 22:06:20 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/28 22:06:20 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/09/28 22:06:20 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/28 22:06:20 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/bigdata/health/tweetsdata.txt:0+13299417
18/09/28 22:06:20 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/28 22:06:20 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/28 22:06:20 INFO mapred.MapTask: soft limit at 83886080
18/09/28 22:06:20 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/28 22:06:20 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/28 22:06:20 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/28 22:06:21 INFO mapreduce.Job: Job job_local899174303_0001 running in uber mode : false
18/09/28 22:06:21 INFO mapreduce.Job:  map 0% reduce 0%
18/09/28 22:06:21 INFO mapred.LocalJobRunner: 
18/09/28 22:06:21 INFO mapred.MapTask: Starting flush of map output
18/09/28 22:06:21 INFO mapred.MapTask: Spilling map output
18/09/28 22:06:21 INFO mapred.MapTask: bufstart = 0; bufend = 15383432; bufvoid = 104857600
18/09/28 22:06:21 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24132676(96530704); length = 2081721/6553600
18/09/28 22:06:22 INFO mapred.MapTask: Finished spill 0
18/09/28 22:06:22 INFO mapred.Task: Task:attempt_local899174303_0001_m_000000_0 is done. And is in the process of committing
18/09/28 22:06:22 INFO mapred.LocalJobRunner: map
18/09/28 22:06:22 INFO mapred.Task: Task 'attempt_local899174303_0001_m_000000_0' done.
18/09/28 22:06:22 INFO mapred.Task: Final Counters for attempt_local899174303_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=302607
		FILE: Number of bytes written=11426285
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=13299417
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=1
		Map output records=520431
		Map output bytes=15383432
		Map output materialized bytes=10747128
		Input split bytes=116
		Combine input records=520431
		Combine output records=278092
		Spilled Records=278092
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=163
		Total committed heap usage (bytes)=435159040
	File Input Format Counters 
		Bytes Read=13299417
18/09/28 22:06:22 INFO mapred.LocalJobRunner: Finishing task: attempt_local899174303_0001_m_000000_0
18/09/28 22:06:22 INFO mapred.LocalJobRunner: Starting task: attempt_local899174303_0001_m_000001_0
18/09/28 22:06:22 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/28 22:06:22 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/09/28 22:06:22 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/28 22:06:22 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/bigdata/health/data3.txt:0+4230895
18/09/28 22:06:22 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/28 22:06:22 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/28 22:06:22 INFO mapred.MapTask: soft limit at 83886080
18/09/28 22:06:22 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/28 22:06:22 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/28 22:06:22 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/28 22:06:23 INFO mapreduce.Job:  map 100% reduce 0%
18/09/28 22:06:23 INFO mapred.LocalJobRunner: 
18/09/28 22:06:23 INFO mapred.MapTask: Starting flush of map output
18/09/28 22:06:23 INFO mapred.MapTask: Spilling map output
18/09/28 22:06:23 INFO mapred.MapTask: bufstart = 0; bufend = 5275759; bufvoid = 104857600
18/09/28 22:06:23 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25169536(100678144); length = 1044861/6553600
18/09/28 22:06:23 INFO mapred.MapTask: Finished spill 0
18/09/28 22:06:23 INFO mapred.Task: Task:attempt_local899174303_0001_m_000001_0 is done. And is in the process of committing
18/09/28 22:06:23 INFO mapred.LocalJobRunner: map
18/09/28 22:06:23 INFO mapred.Task: Task 'attempt_local899174303_0001_m_000001_0' done.
18/09/28 22:06:23 INFO mapred.Task: Final Counters for attempt_local899174303_0001_m_000001_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=303189
		FILE: Number of bytes written=13510742
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17530312
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=1
		Map output records=261216
		Map output bytes=5275759
		Map output materialized bytes=2084425
		Input split bytes=111
		Combine input records=261216
		Combine output records=80548
		Spilled Records=80548
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=60
		Total committed heap usage (bytes)=427294720
	File Input Format Counters 
		Bytes Read=4230895
18/09/28 22:06:23 INFO mapred.LocalJobRunner: Finishing task: attempt_local899174303_0001_m_000001_0
18/09/28 22:06:23 INFO mapred.LocalJobRunner: Starting task: attempt_local899174303_0001_m_000002_0
18/09/28 22:06:23 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/28 22:06:23 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/09/28 22:06:23 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/28 22:06:23 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/bigdata/health/Yoga.txt:0+1857649
18/09/28 22:06:23 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/28 22:06:23 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/28 22:06:23 INFO mapred.MapTask: soft limit at 83886080
18/09/28 22:06:23 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/28 22:06:23 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/28 22:06:23 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/28 22:06:24 INFO mapred.LocalJobRunner: 
18/09/28 22:06:24 INFO mapred.MapTask: Starting flush of map output
18/09/28 22:06:24 INFO mapred.MapTask: Spilling map output
18/09/28 22:06:24 INFO mapred.MapTask: bufstart = 0; bufend = 2426617; bufvoid = 104857600
18/09/28 22:06:24 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25645432(102581728); length = 568965/6553600
18/09/28 22:06:24 INFO mapred.MapTask: Finished spill 0
18/09/28 22:06:24 INFO mapred.Task: Task:attempt_local899174303_0001_m_000002_0 is done. And is in the process of committing
18/09/28 22:06:24 INFO mapred.LocalJobRunner: map
18/09/28 22:06:24 INFO mapred.Task: Task 'attempt_local899174303_0001_m_000002_0' done.
18/09/28 22:06:24 INFO mapred.Task: Final Counters for attempt_local899174303_0001_m_000002_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=303771
		FILE: Number of bytes written=14532667
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=19387961
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=1
		Map output records=142242
		Map output bytes=2426617
		Map output materialized bytes=1021893
		Input split bytes=110
		Combine input records=142242
		Combine output records=41954
		Spilled Records=41954
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=824
		Total committed heap usage (bytes)=503840768
	File Input Format Counters 
		Bytes Read=1857649
18/09/28 22:06:24 INFO mapred.LocalJobRunner: Finishing task: attempt_local899174303_0001_m_000002_0
18/09/28 22:06:24 INFO mapred.LocalJobRunner: Starting task: attempt_local899174303_0001_m_000003_0
18/09/28 22:06:24 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/28 22:06:24 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/09/28 22:06:24 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/28 22:06:24 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/bigdata/health/data1.txt:0+1847775
18/09/28 22:06:24 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/28 22:06:24 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/28 22:06:24 INFO mapred.MapTask: soft limit at 83886080
18/09/28 22:06:24 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/28 22:06:24 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/28 22:06:24 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/28 22:06:24 INFO mapred.LocalJobRunner: 
18/09/28 22:06:24 INFO mapred.MapTask: Starting flush of map output
18/09/28 22:06:24 INFO mapred.MapTask: Spilling map output
18/09/28 22:06:24 INFO mapred.MapTask: bufstart = 0; bufend = 2414443; bufvoid = 104857600
18/09/28 22:06:24 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25647732(102590928); length = 566665/6553600
18/09/28 22:06:25 INFO mapred.MapTask: Finished spill 0
18/09/28 22:06:25 INFO mapred.Task: Task:attempt_local899174303_0001_m_000003_0 is done. And is in the process of committing
18/09/28 22:06:25 INFO mapred.LocalJobRunner: map
18/09/28 22:06:25 INFO mapred.Task: Task 'attempt_local899174303_0001_m_000003_0' done.
18/09/28 22:06:25 INFO mapred.Task: Final Counters for attempt_local899174303_0001_m_000003_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=304353
		FILE: Number of bytes written=15549805
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=21235736
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=1
		Map output records=141667
		Map output bytes=2414443
		Map output materialized bytes=1017106
		Input split bytes=111
		Combine input records=141667
		Combine output records=41793
		Spilled Records=41793
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=63
		Total committed heap usage (bytes)=528482304
	File Input Format Counters 
		Bytes Read=1847775
18/09/28 22:06:25 INFO mapred.LocalJobRunner: Finishing task: attempt_local899174303_0001_m_000003_0
18/09/28 22:06:25 INFO mapred.LocalJobRunner: Starting task: attempt_local899174303_0001_m_000004_0
18/09/28 22:06:25 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/28 22:06:25 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/09/28 22:06:25 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/28 22:06:25 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/bigdata/health/data2.txt:0+1618776
18/09/28 22:06:25 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/28 22:06:25 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/28 22:06:25 INFO mapred.MapTask: soft limit at 83886080
18/09/28 22:06:25 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/28 22:06:25 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/28 22:06:25 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/28 22:06:25 INFO mapred.LocalJobRunner: 
18/09/28 22:06:25 INFO mapred.MapTask: Starting flush of map output
18/09/28 22:06:25 INFO mapred.MapTask: Spilling map output
18/09/28 22:06:25 INFO mapred.MapTask: bufstart = 0; bufend = 2080092; bufvoid = 104857600
18/09/28 22:06:25 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25753084(103012336); length = 461313/6553600
18/09/28 22:06:25 INFO mapred.MapTask: Finished spill 0
18/09/28 22:06:25 INFO mapred.Task: Task:attempt_local899174303_0001_m_000004_0 is done. And is in the process of committing
18/09/28 22:06:25 INFO mapred.LocalJobRunner: map
18/09/28 22:06:25 INFO mapred.Task: Task 'attempt_local899174303_0001_m_000004_0' done.
18/09/28 22:06:25 INFO mapred.Task: Final Counters for attempt_local899174303_0001_m_000004_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=304935
		FILE: Number of bytes written=16280896
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=22854512
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=1
		Map output records=115329
		Map output bytes=2080092
		Map output materialized bytes=731059
		Input split bytes=111
		Combine input records=115329
		Combine output records=29734
		Spilled Records=29734
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=66
		Total committed heap usage (bytes)=528482304
	File Input Format Counters 
		Bytes Read=1618776
18/09/28 22:06:25 INFO mapred.LocalJobRunner: Finishing task: attempt_local899174303_0001_m_000004_0
18/09/28 22:06:25 INFO mapred.LocalJobRunner: map task executor complete.
18/09/28 22:06:25 INFO mapred.LocalJobRunner: Waiting for reduce tasks
18/09/28 22:06:25 INFO mapred.LocalJobRunner: Starting task: attempt_local899174303_0001_r_000000_0
18/09/28 22:06:25 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/28 22:06:25 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/09/28 22:06:25 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/28 22:06:25 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4f2609e2
18/09/28 22:06:25 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=369937600, maxSingleShuffleLimit=92484400, mergeThreshold=244158832, ioSortFactor=10, memToMemMergeOutputsThreshold=10
18/09/28 22:06:25 INFO reduce.EventFetcher: attempt_local899174303_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
18/09/28 22:06:25 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local899174303_0001_m_000004_0 decomp: 731055 len: 731059 to MEMORY
18/09/28 22:06:25 INFO reduce.InMemoryMapOutput: Read 731055 bytes from map-output for attempt_local899174303_0001_m_000004_0
18/09/28 22:06:25 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 731055, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->731055
18/09/28 22:06:25 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local899174303_0001_m_000001_0 decomp: 2084421 len: 2084425 to MEMORY
18/09/28 22:06:25 INFO reduce.InMemoryMapOutput: Read 2084421 bytes from map-output for attempt_local899174303_0001_m_000001_0
18/09/28 22:06:25 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2084421, inMemoryMapOutputs.size() -> 2, commitMemory -> 731055, usedMemory ->2815476
18/09/28 22:06:25 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local899174303_0001_m_000002_0 decomp: 1021889 len: 1021893 to MEMORY
18/09/28 22:06:25 INFO reduce.InMemoryMapOutput: Read 1021889 bytes from map-output for attempt_local899174303_0001_m_000002_0
18/09/28 22:06:25 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1021889, inMemoryMapOutputs.size() -> 3, commitMemory -> 2815476, usedMemory ->3837365
18/09/28 22:06:25 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local899174303_0001_m_000000_0 decomp: 10747124 len: 10747128 to MEMORY
18/09/28 22:06:25 INFO reduce.InMemoryMapOutput: Read 10747124 bytes from map-output for attempt_local899174303_0001_m_000000_0
18/09/28 22:06:25 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 10747124, inMemoryMapOutputs.size() -> 4, commitMemory -> 3837365, usedMemory ->14584489
18/09/28 22:06:25 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local899174303_0001_m_000003_0 decomp: 1017102 len: 1017106 to MEMORY
18/09/28 22:06:25 INFO reduce.InMemoryMapOutput: Read 1017102 bytes from map-output for attempt_local899174303_0001_m_000003_0
18/09/28 22:06:25 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1017102, inMemoryMapOutputs.size() -> 5, commitMemory -> 14584489, usedMemory ->15601591
18/09/28 22:06:25 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
18/09/28 22:06:25 INFO mapred.LocalJobRunner: 5 / 5 copied.
18/09/28 22:06:25 INFO reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs
18/09/28 22:06:25 INFO mapred.Merger: Merging 5 sorted segments
18/09/28 22:06:25 INFO mapred.Merger: Down to the last merge-pass, with 5 segments left of total size: 15601552 bytes
18/09/28 22:06:26 INFO reduce.MergeManagerImpl: Merged 5 segments, 15601591 bytes to disk to satisfy reduce memory limit
18/09/28 22:06:26 INFO reduce.MergeManagerImpl: Merging 1 files, 15601587 bytes from disk
18/09/28 22:06:26 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
18/09/28 22:06:26 INFO mapred.Merger: Merging 1 sorted segments
18/09/28 22:06:26 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 15601573 bytes
18/09/28 22:06:26 INFO mapred.LocalJobRunner: 5 / 5 copied.
18/09/28 22:06:26 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
18/09/28 22:06:27 INFO mapred.Task: Task:attempt_local899174303_0001_r_000000_0 is done. And is in the process of committing
18/09/28 22:06:27 INFO mapred.LocalJobRunner: 5 / 5 copied.
18/09/28 22:06:27 INFO mapred.Task: Task attempt_local899174303_0001_r_000000_0 is allowed to commit now
18/09/28 22:06:27 INFO output.FileOutputCommitter: Saved output of task 'attempt_local899174303_0001_r_000000_0' to hdfs://localhost:9000/output/health/_temporary/0/task_local899174303_0001_r_000000
18/09/28 22:06:27 INFO mapred.LocalJobRunner: reduce > reduce
18/09/28 22:06:27 INFO mapred.Task: Task 'attempt_local899174303_0001_r_000000_0' done.
18/09/28 22:06:27 INFO mapred.Task: Final Counters for attempt_local899174303_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=31508293
		FILE: Number of bytes written=31882483
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=22854512
		HDFS: Number of bytes written=11737345
		HDFS: Number of read operations=20
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=372298
		Reduce shuffle bytes=15601611
		Reduce input records=472121
		Reduce output records=372298
		Spilled Records=472121
		Shuffled Maps =5
		Failed Shuffles=0
		Merged Map outputs=5
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=527433728
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=11737345
18/09/28 22:06:27 INFO mapred.LocalJobRunner: Finishing task: attempt_local899174303_0001_r_000000_0
18/09/28 22:06:27 INFO mapred.LocalJobRunner: reduce task executor complete.
18/09/28 22:06:27 INFO mapreduce.Job:  map 100% reduce 100%
18/09/28 22:06:27 INFO mapreduce.Job: Job job_local899174303_0001 completed successfully
18/09/28 22:06:27 INFO mapreduce.Job: Counters: 35
	File System Counters
		FILE: Number of bytes read=33027148
		FILE: Number of bytes written=103182878
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=117162450
		HDFS: Number of bytes written=11737345
		HDFS: Number of read operations=85
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Map-Reduce Framework
		Map input records=5
		Map output records=1180885
		Map output bytes=27580343
		Map output materialized bytes=15601611
		Input split bytes=559
		Combine input records=1180885
		Combine output records=472121
		Reduce input groups=372298
		Reduce shuffle bytes=15601611
		Reduce input records=472121
		Reduce output records=372298
		Spilled Records=944242
		Shuffled Maps =5
		Failed Shuffles=0
		Merged Map outputs=5
		GC time elapsed (ms)=1179
		Total committed heap usage (bytes)=2950692864
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=22854512
	File Output Format Counters 
		Bytes Written=11737345

